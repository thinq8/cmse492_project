{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3b5c016",
   "metadata": {},
   "source": [
    "# League of Legends Early-Game EDA\n",
    "\n",
    "This notebook delivers the exploratory analysis and baseline modeling required by the CMSE 492 Project Setup and Proposal assignment. The workflow establishes a clean train/test split, profiles the dataset, surfaces outcome-driven patterns, and records a simple baseline—all prerequisites for the upcoming project proposal and milestone planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0907f9",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "The assignment specifies using the scientific Python stack listed in `requirements.txt`. We load it here and configure plotting for consistent styling, even in headless environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4308a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Keep plots deterministic across local/remote runs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a5118",
   "metadata": {},
   "source": [
    "## 2. Data Source and Loading\n",
    "\n",
    "Per the requirements, we document provenance before analysis. The dataset comes from Kaggle's *League of Legends Diamond Ranked Games (10 min)* collection, which aggregates high-level ranked matches with team statistics captured through the first ten minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eabd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = Path('data/raw/high_diamond_ranked_10min.csv')\n",
    "if not RAW_PATH.exists():\n",
    "    raise FileNotFoundError(f'Dataset missing at {RAW_PATH}')\n",
    "\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7a181",
   "metadata": {},
   "source": [
    "We capture fundamental metadata—table shape and column data types—so the proposal can state the dataset size and feature mix explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0cfec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = df.shape\n",
    "df_dtypes = df.dtypes.to_frame('dtype')\n",
    "df_shape, df_dtypes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71529c",
   "metadata": {},
   "source": [
    "The assignment also requests saving a sample to `data/processed/` for quick inspection by reviewers or teammates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64653bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = Path('data/processed')\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "sample_path = processed_dir / 'sample_matches.csv'\n",
    "df.sample(n=200, random_state=42).to_csv(sample_path, index=False)\n",
    "sample_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b863e239",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split\n",
    "\n",
    "We follow the requirement to split data prior to deeper EDA, reserving 20% of matches for a held-out set and stratifying on the binary target `blueWins` to preserve class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbf20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'blueWins'\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=TEST_SIZE,\n",
    "    stratify=df[TARGET],\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445bdea2",
   "metadata": {},
   "source": [
    "## 4. Dataset Profile\n",
    "\n",
    "We record the core profiling statistics—row counts, feature counts, class balance, and missingness—for reuse in the proposal's Data Description section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe8ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = {\n",
    "    'train_rows': int(train_df.shape[0]),\n",
    "    'test_rows': int(test_df.shape[0]),\n",
    "    'n_features': int(train_df.shape[1] - 1),\n",
    "    'class_balance_train': train_df[TARGET].value_counts(normalize=True).round(4).to_dict(),\n",
    "    'missing_rates': train_df.isnull().mean().round(4).to_dict(),\n",
    "}\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bfb47e",
   "metadata": {},
   "source": [
    "### Descriptive Statistics\n",
    "\n",
    "Numerical summaries help flag anomalous ranges and guide scaling choices for baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378749a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_summary = train_df.select_dtypes(include=[np.number]).describe().T\n",
    "numeric_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed5ebe",
   "metadata": {},
   "source": [
    "### Missingness Visualization\n",
    "\n",
    "Even though this dataset is known to be complete, we include a visualization to explicitly document the absence of missing values, fulfilling the EDA checklist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_dir = Path('figures/eda')\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "missing_rates = pd.Series(profile['missing_rates']).sort_values(ascending=False)\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "missing_rates.head(15).plot(kind='bar', ax=ax, color='#7570b3')\n",
    "ax.set_ylabel('Fraction Missing')\n",
    "ax.set_title('Top Feature Missingness (Train Split)')\n",
    "fig.tight_layout()\n",
    "fig.savefig(figures_dir / 'missingness.png', dpi=300)\n",
    "plt.close(fig)\n",
    "missing_rates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c350f",
   "metadata": {},
   "source": [
    "## 5. Target Correlations\n",
    "\n",
    "Correlations with `blueWins` inform which signals (e.g., gold and experience advantages) should be prioritized in baseline models and hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605338ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_target = (\n",
    "    train_df.select_dtypes(include=[np.number]).corr()[TARGET]\n",
    "    .drop(TARGET)\n",
    "    .sort_values(key=lambda s: s.abs(), ascending=False)\n",
    ")\n",
    "corr_with_target.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad97f68",
   "metadata": {},
   "source": [
    "## 6. Visual Diagnostics\n",
    "\n",
    "These figures will feed directly into the proposal's Data Description and Motivation sections, highlighting class balance, feature distributions, objective control, and feature interplay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "class_counts = train_df[TARGET].value_counts().sort_index()\n",
    "ax.bar(['Red Wins (0)', 'Blue Wins (1)'], class_counts.values, color=['#d95f02', '#1b9e77'])\n",
    "ax.set_ylabel('Match Count')\n",
    "ax.set_title('Train Split Class Balance')\n",
    "for label, count in zip(['Red Wins (0)', 'Blue Wins (1)'], class_counts.values):\n",
    "    ax.annotate(f'{count}', (label, count), ha='center', va='bottom', fontsize=9)\n",
    "fig.tight_layout()\n",
    "fig.savefig(figures_dir / 'class_balance.png', dpi=300)\n",
    "plt.close(fig)\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions\n",
    "key_features = [\n",
    "    'blueGoldDiff',\n",
    "    'blueExperienceDiff',\n",
    "    'blueKills',\n",
    "    'blueDeaths',\n",
    "    'blueEliteMonsters',\n",
    "    'blueDragons',\n",
    "    'blueTowersDestroyed',\n",
    "]\n",
    "fig, axes = plt.subplots(len(key_features), 1, figsize=(7, 2.6 * len(key_features)))\n",
    "for feature, ax in zip(key_features, axes):\n",
    "    sns.histplot(\n",
    "        train_df,\n",
    "        x=feature,\n",
    "        hue=TARGET,\n",
    "        element='step',\n",
    "        stat='density',\n",
    "        common_norm=False,\n",
    "        palette=['#d95f02', '#1b9e77'],\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(f'Distribution of {feature} by Match Outcome')\n",
    "fig.tight_layout()\n",
    "fig.savefig(figures_dir / 'feature_distributions.png', dpi=300)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c0ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective control comparison\n",
    "objective_features = ['blueDragons', 'blueHeralds', 'blueEliteMonsters', 'blueTowersDestroyed']\n",
    "obj_stats = (\n",
    "    train_df.groupby(TARGET)[objective_features]\n",
    "    .mean()\n",
    "    .rename(index={0: 'Red Victory', 1: 'Blue Victory'})\n",
    "    .T\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(7.5, 4.2))\n",
    "obj_stats.plot(kind='bar', ax=ax, color=['#d95f02', '#1b9e77'])\n",
    "ax.set_ylabel('Average Count (First 10 Minutes)')\n",
    "ax.set_title('Objective Control by Winning Team')\n",
    "ax.legend(title='Outcome')\n",
    "fig.tight_layout()\n",
    "fig.savefig(figures_dir / 'objective_control.png', dpi=300)\n",
    "plt.close(fig)\n",
    "obj_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c528cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "selected = list(corr_with_target.head(12).index) + [TARGET]\n",
    "corr_matrix = train_df[selected].corr()\n",
    "fig, ax = plt.subplots(figsize=(9, 7))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    cbar_kws={'shrink': 0.7},\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_title('Correlation Heatmap: Top Outcome-Linked Features')\n",
    "fig.tight_layout()\n",
    "fig.savefig(figures_dir / 'top_feature_correlation_heatmap.png', dpi=300)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d69fb",
   "metadata": {},
   "source": [
    "## 7. Outlier Assessment\n",
    "\n",
    "We evaluate interquartile ranges for the primary advantage metrics. Low outlier fractions reinforce that models can work with raw counts (after optional scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ed51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_features = ['blueGoldDiff', 'blueExperienceDiff', 'blueKills']\n",
    "outlier_summary = {}\n",
    "for feat in outlier_features:\n",
    "    series = train_df[feat]\n",
    "    q1, q3 = series.quantile([0.25, 0.75])\n",
    "    iqr = float(q3 - q1)\n",
    "    lower = float(q1 - 1.5 * iqr)\n",
    "    upper = float(q3 + 1.5 * iqr)\n",
    "    outliers = series[(series < lower) | (series > upper)]\n",
    "    outlier_summary[feat] = {\n",
    "        'iqr': iqr,\n",
    "        'lower_bound': lower,\n",
    "        'upper_bound': upper,\n",
    "        'outlier_fraction': float(len(outliers) / len(series)),\n",
    "    }\n",
    "outlier_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b2686",
   "metadata": {},
   "source": [
    "## 8. Baseline Models\n",
    "\n",
    "The homework requires a simple baseline model. We compare a majority-class `DummyClassifier` with a regularized logistic regression pipeline to establish reference metrics (accuracy, F1, ROC-AUC). `gameId` is excluded because it is an identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1eebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in train_df.columns if col not in {TARGET, 'gameId'}]\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[TARGET]\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df[TARGET]\n",
    "\n",
    "baseline_results = {}\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "baseline_results['dummy_majority'] = {\n",
    "    'accuracy': float(accuracy_score(y_test, y_pred_dummy)),\n",
    "    'f1': float(f1_score(y_test, y_pred_dummy, zero_division=0)),\n",
    "}\n",
    "\n",
    "log_reg = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(max_iter=1000, solver='lbfgs'))\n",
    "    ]\n",
    ")\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "y_proba_lr = log_reg.predict_proba(X_test)[:, 1]\n",
    "baseline_results['logistic_regression'] = {\n",
    "    'accuracy': float(accuracy_score(y_test, y_pred_lr)),\n",
    "    'f1': float(f1_score(y_test, y_pred_lr)),\n",
    "    'roc_auc': float(roc_auc_score(y_test, y_proba_lr)),\n",
    "}\n",
    "\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408567e0",
   "metadata": {},
   "source": [
    "## 9. Persist Outputs\n",
    "\n",
    "To keep the repo reproducible, we persist summaries, split metadata, outlier stats, baseline metrics, and the sample dataset under `data/processed/`. Charts are already saved under `figures/eda/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3776fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(processed_dir / 'eda_summary.json').write_text(json.dumps(profile, indent=2))\n",
    "numeric_summary.round(3).to_csv(processed_dir / 'numeric_feature_summary.csv')\n",
    "split_meta = {\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'test_size': TEST_SIZE,\n",
    "    'stratified': True,\n",
    "    'train_count': int(train_df.shape[0]),\n",
    "    'test_count': int(test_df.shape[0]),\n",
    "}\n",
    "(processed_dir / 'split_metadata.json').write_text(json.dumps(split_meta, indent=2))\n",
    "(processed_dir / 'outlier_summary.json').write_text(json.dumps(outlier_summary, indent=2))\n",
    "(processed_dir / 'baseline_metrics.json').write_text(json.dumps(baseline_results, indent=2))\n",
    "sorted(p.name for p in processed_dir.glob('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850e8cd8",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways for Modeling\n",
    "\n",
    "- Blue vs. red wins remain perfectly balanced, so class reweighting is optional.\n",
    "- Gold and experience differentials dominate the signal (|corr| ≈ 0.5), guiding feature importance   expectations for tree ensembles and neural nets.\n",
    "- Objective control (dragons, heralds, towers) differentiates outcomes, suggesting engineered difference   features could boost models.\n",
    "- Logistic regression already beats the majority baseline, validating that even linear models capture   early-game signals—useful when benchmarking more complex approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
